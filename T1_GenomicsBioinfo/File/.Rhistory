pi_S <- pi_S +sum(abs(data_S[i,]-data_S[j,]))
}
}
# divide by the nr of comparisons done
pi_S <- pi_S / ((n*(n-1))/2)
## now that you have theta you can estimate Ne using equation 14 on the slides
# remember to multiple the mutation rate 1e-8 with the length your sequence before plugging it into the quation
Ne_N_pi <- pi_N / (4*mu*len) # 460.5263
Ne_S_pi <- pi_S / (4*mu*len) # 47.36842
Ne_N_pi
Ne_S_pi
len <- 50000
data_N <- as.matrix(read.csv("../Data/killer_whale_North.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data_N)
data_S <- as.matrix(read.csv("../Data/killer_whale_South.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data_S)
n <- nrow(data_N) # nr of samples (chromosomes)
pi_N <- 0
for (i in 1:(n-1)) {
for (j in (i+1):n) {
pi_N <- pi_N + sum(abs(data_N[i,]-data_N[j,]))
}
}
pi_N <- pi_N / ((n*(n-1))/2)
n <- nrow(data_S) # nr of samples (chromosomes)
pi_S <- 0
for (i in 1:(n-1)) {
for (j in (i+1):n) {
pi_S <- pi_S + sum(abs(data_S[i,]-data_S[j,]))
}
}
pi_S <- pi_S / ((n*(n-1))/2)
## estimates of Ne from Tajima's estimator
Ne_N_pi <- pi_N / (4 * 1e-8 * len)
Ne_S_pi <- pi_S / (4 * 1e-8 * len)
Ne_N_pi
Ne_S_pi
# repeat the same procedure to calculate pi_S (Tajima's estimator of theta for the Northern population)
n <- nrow(data_S)
pi_S <- 0
for (i in 1:(n-1)) { # loop of i
for (j in (i+1):n) {
pi_S <- pi_S +sum(abs(data_S[i,]-data_S[j,]))
}
}
# divide by the nr of comparisons done
pi_S <- pi_S / ((n*(n-1))/2)
## now that you have theta you can estimate Ne using equation 14 on the slides
# remember to multiple the mutation rate 1e-8 with the length your sequence before plugging it into the quation
Ne_N_pi <- pi_N / (4*mu*len) # 4634.211
Ne_S_pi <- pi_S / (4*mu*len) # 47.36842
Ne_S_pi
### calculate nr of SNPs and then the estimator
freqs <- apply(X=data_N, MAR=2, FUN=sum)/nrow(data_N)
snps_N <- length(which(freqs>0 & freqs<1))
watt_N <- snps_N / sum(1/seq(1,n-1))
freqs
unique(freqs)
apply(X=data_N, MAR=2, FUN=sum)
?aapply(array, margin, ...)
?apply
length(which(freqs>0 & freqs<1))
S_N <- length(which(freqs>0 & freqs<1))
S_N
# repeat the same procedure for S population
freqs_S <- apply(data_S, 2, sum)
S_S <- length(which(freqs_S>0 & freqs_S<1))
watt_S <- S_S/ sum(1/seq(1:n-1))
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- (4*mu*len)
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- S_N/(4*mu*len)
Ne_S_watt <- S_S/(4*mu*len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
freqs <- apply(X=data_N, MAR=2, FUN=sum)/nrow(data_N)
snps_N <- length(which(freqs>0 & freqs<1))
watt_N <- snps_N / sum(1/seq(1,n-1))
freqs <- apply(X=data_S, MAR=2, FUN=sum)/nrow(data_S)
snps_S <- length(which(freqs>0 & freqs<1))
watt_S <- snps_S / sum(1/seq(1,n-1))
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- watt_N / (4 * 1e-8 * len)
Ne_S_watt <- watt_S / (4 * 1e-8 * len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
# use equation 20 calculate watterson estimator
watt_N <- S_N / sum(1/seq(1,(n-1)))
# repeat the same procedure for S population
freqs_S <- apply(data_S, 2, sum)
S_S <- length(which(freqs_S>0 & freqs_S<1))
watt_S <- S_S/ sum(1/seq(1:(n-1)))
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- S_N/(4*mu*len)
Ne_S_watt <- S_S/(4*mu*len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
# repeat the same procedure for S population
freqs_S <- apply(data_S, 2, sum) / nrow(data_S)
S_S <- length(which(freqs_S>0 & freqs_S<1))
watt_S <- S_S / sum(1/seq(1:(n-1)))
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- S_N/(4*mu*len)
Ne_S_watt <- S_S/(4*mu*len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
freqs <- apply(X=data_N, MAR=2, FUN=sum)/nrow(data_N)
snps_N <- length(which(freqs>0 & freqs<1))
watt_N <- snps_N / sum(1/seq(1,n-1))
freqs <- apply(X=data_S, MAR=2, FUN=sum)/nrow(data_S)
snps_S <- length(which(freqs>0 & freqs<1))
watt_S <- snps_S / sum(1/seq(1,n-1))
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- watt_N / (4 * 1e-8 * len)
Ne_S_watt <- watt_S / (4 * 1e-8 * len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
### estimates of Ne from Wattersons' estimator
Ne_N_watt <- watt_N/(4*mu*len)
Ne_S_watt <- watt_S/(4*mu*len)
cat("\nThe North population has estimates of effective population size of", Ne_N_pi, "and", Ne_N_watt)
cat("\nThe South population has estimates of effective population size of", Ne_S_pi, "and", Ne_S_watt)
### North population
sfs_N <- rep(0, n-1) # initialise a vector from 0 to n-1
sfs_N
n
### calculate allele frequencies using the apply functions as previously shown
derived_freqs <- apply(data_N, 2, sum)
freq <- derived_freqs / n
freq
derived_freqs
### calculate allele frequencies using the apply functions as previously shown
derived_freqs <- apply(data_N, 2, sum) / n
unique(derived_freqs)
length(derived_freqs)
length(unique(derived_freqs))
### North population
sfs_N <- rep(0, n-1) # initialise a vector from 0 to n-1
### calculate allele frequencies using the apply functions as previously shown
derived_freqs <- apply(data_N, 2, sum) / n
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences of each possible allele frequency
for (i in 1:length(unique(derived_freqs))) sfs_N[i] <- length(which(derived_freqs == derived_freqs[i]))
### South population
# repeat as above
sfs_S <- rep(0, n-1)
derived_freqs <- apply(data_S, 2, sum) / n
for (i in 1:length(unique(derived_freqs))) sfs_S[i] <- length(which(derived_freqs == derived_freqs[i]))
### plot
barplot(sfs_N) # or use any other plotting functions
barplot(sfs_S)
### North population
sfs_N <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_N, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_N)) sfs_N[i] <- length(which(derived_freqs==i))
### South population
sfs_S <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_S, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_S)) sfs_S[i] <- length(which(derived_freqs==i))
### plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(data_S)-1,1), legend=c("North", "South"))
cat("\nThe population with the greater population size has a higher proportion of singletons, as expected.")
sfs <- matrix(0, nrow=nrow(data_N)+1, ncol=nrow(data_S)+1)
for (i in 1:ncol(data_N)) {
freq_N <- sum(data_N[,i])
freq_S <- sum(data_S[,i])
sfs[freq_N+1,freq_S+1] <- sfs[freq_N+1,freq_S+1] + 1
}
sfs[1,1] <- NA # ignore non-SNPs
image(t(sfs))
### North population
f_N <- rep(0, n-1) # initialise a vector from 0 to n-1
### calculate allele frequencies using the apply functions as previously shown
derived_freqs <- apply(data_N, 2, sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences of each possible allele frequency
for (i in 1:n-1) f_N[i] <- length(which(derived_freqs == i))
### North population
f_N <- rep(0, n-1) # initialise a vector from 0 to n-1
### calculate allele frequencies using the apply functions as previously shown
derived_freqs <- apply(data_N, 2, sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences of each possible allele frequency
for (i in 1:(n-1)) f_N[i] <- length(which(derived_freqs == i))
### South population
# repeat as above
f_S <- rep(0, n-1)
derived_freqs <- apply(data_S, 2, sum)
for (i in 1:(n-1)) f_S[i] <- length(which(derived_freqs == derived_freqs[i]))
### plot
barplot(sfs_N) # or use any other plotting functions
barplot(sfs_S)
### plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(data_S)-1,1), legend=c("North", "South"))
### North population
sfs_N <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_N, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_N)) sfs_N[i] <- length(which(derived_freqs==i))
### South population
sfs_S <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_S, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_S)) sfs_S[i] <- length(which(derived_freqs==i))
### plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(data_S)-1,1), legend=c("North", "South"))
cat("\nThe population with the greater population size has a higher proportion of singletons, as expected.")
### plot
barplot(t(cbind(f_N, f_S)))# or use any other plotting functions
### plot
barplot(f_N)
barplot(t(cbind(f_N, f_S)), beside=T)# or use any other plotting functions
barplot(f_S)
f_S
f_N
### South population
# repeat as above
f_S <- rep(0, n-1)
derived_freqs <- apply(data_S, 2, sum)
for (i in 1:(n-1)) f_S[i] <- length(which(derived_freqs == i))
### plot
barplot(f_N)
barplot(f_S)
barplot(t(cbind(f_N, f_S)), beside=T)# or use any other plotting functions
f_S <- f_S/sum(f_S)
barplot(f_S)
f_N <- f_N/sum(f_N)
barplot(t(cbind(f_N, f_S)), beside=T)
sfs <- matrix(0, nrow=nrow(data_N)+1, ncol=nrow(data_S)+1)
for (i in 1:ncol(data_N)) {
freq_N <- sum(data_N[,i])
freq_S <- sum(data_S[,i])
sfs[freq_N+1,freq_S+1] <- sfs[freq_N+1,freq_S+1] + 1
}
sfs[1,1] <- NA # ignore non-SNPs
image(t(sfs))
### read data
len <- 2000
data <- as.matrix(read.csv("../Data/turtle.genotypes.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data)
### assign an name for each location
locations <- rep(c("A","B","C","D"), each=10)
### read data
len <- 2000
data <- as.matrix(read.csv("../Data/turtle.genotypes.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data)
### assign an name for each location
locations <- rep(c("A","B","C","D"), each=10)
View(data)
distance <- dist(data)
distance
tree <- hclust(distance)
View(tree)
plot(tree, labels=locations)
### or we can do a PCA
### we can filter our low-frequency variants first
colors <- rep(c("blue","red","yellow","green"), each=10)
index <- which(apply(FUN=sum, X=data, MAR=2)/(nrow(data)*2)>0.05)
pca <- prcomp(data[,index], center=T, scale=T)
summary(pca)
plot(pca$x[,1], pca$x[,2], col=colors, pch=1)
legend("right", legend=sort(unique(locations)), col=unique(colors), pch=1)
data2 <- as.matrix(read.csv("../turtle.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
calcFST <- function(pop1, pop2) {
# only for equal sample sizes!
fA1 <- as.numeric(apply(FUN=sum, X=pop1, MAR=2)/nrow(pop1))
fA2 <- as.numeric(apply(FUN=sum, X=pop2, MAR=2)/nrow(pop2))
FST <- rep(NA, length(fA1))
for (i in 1:length(FST)) {
HT <- 2 * ( (fA1[i] + fA2[i]) / 2 ) * (1 - ((fA1[i] + fA2[i]) / 2) )
HS <- fA1[i] * (1 - fA1[i]) + fA2[i] * (1 - fA2[i])
FST[i] <- (HT - HS) / HT
}
FST
}
snps <- which(apply(FUN=sum, X=data2, MAR=2)/(nrow(data2))>0.05)
data2 <- as.matrix(read.csv("../Data/turtle.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
calcFST <- function(pop1, pop2) {
# only for equal sample sizes!
fA1 <- as.numeric(apply(FUN=sum, X=pop1, MAR=2)/nrow(pop1))
fA2 <- as.numeric(apply(FUN=sum, X=pop2, MAR=2)/nrow(pop2))
FST <- rep(NA, length(fA1))
for (i in 1:length(FST)) {
HT <- 2 * ( (fA1[i] + fA2[i]) / 2 ) * (1 - ((fA1[i] + fA2[i]) / 2) )
HS <- fA1[i] * (1 - fA1[i]) + fA2[i] * (1 - fA2[i])
FST[i] <- (HT - HS) / HT
}
FST
}
snps <- which(apply(FUN=sum, X=data2, MAR=2)/(nrow(data2))>0.05)
cat("\nFST value (average):",
"\nA vs B", mean(calcFST(data2[1:20,snps], data2[21:40,snps]), na.rm=T),
"\nA vs C", mean(calcFST(data2[1:20,snps], data2[41:60,snps]), na.rm=T),
"\nA vs D", mean(calcFST(data2[1:20,snps], data2[61:80,snps]), na.rm=T),
"\nB vs C", mean(calcFST(data2[21:40,snps], data2[41:60,snps]), na.rm=T),
"\nB vs D", mean(calcFST(data2[21:40,snps], data2[61:80,snps]), na.rm=T),
"\nC vs D", mean(calcFST(data2[41:60,snps], data2[61:80,snps]), na.rm=T),"\n")
## 2) there is no evidence for isolation by distance, but instead of admixture
locations
?dist
x <- matrix(rnorm(100), nrow = 5)
dist(x)
dist(x, diag = TRUE)
dist(x, upper = TRUE)
m <- as.matrix(dist(x))
d <- as.dist(m)
stopifnot(d == dist(x)
)
m
d
?prcomp
setwd("~/Documents/CMEE_T2/T1_GenomicsBioinfo/File")
## 1) identify which positions are SNPs
### read data
data <- read.csv("../Data/bears.csv", stringsAsFactors=F, header=F, colClasses=rep("character", 10000))
dim(data)
### SNPs are positions where you observed more than one allele
### the easiest thing is to loop over all sites and record the ones with two alleles
snps <- c()
for (i in 1:ncol(data)) {
if (length(unique(data[,i]))==2) {
snps <- c(snps, i)
}
}
View(data)
### this works to retain the indexes of SNPs;
### a smartest way would not involve doing a loop but using `apply` functions
cat("\nNumber of SNPs is", length(snps))
### reduce the data set
data <- data[,snps]
dim(data)
### again we can loop over each SNP and easily calculate allele frequencies
frequencies <- c()
for (i in 1:ncol(data)) {
### alleles in this SNPs
alleles <- sort(unique(data[,i]))
cat("\nSNP", i, "with alleles", alleles)
### we have to make a decision on which allele to consider to calculate its frequency;
### for instance, after we sort them, we can pick the second one (but the choice at this stage is arbitrary)
### frequency (of the second allele)
freq <- length(which(data[,i]==alleles[2])) / nrow(data)
cat(" and allele frequency of the second allele is", freq)
frequencies <- c(frequencies, freq)
}
### we can plot is as a histogram
hist(frequencies)
### or simply the frequencies at each position
plot(frequencies, type="h")
### again, we can loop over each SNPs and each individual and print the genotype frequencies
nsamples <- 20
for (i in 1:ncol(data)) {
### alleles in this SNPs
alleles <- sort(unique(data[,i]))
cat("\nSNP", i, "with alleles", alleles)
### as before, I can choose one allele as "reference"
### genotypes are Allele1/Allele1 Allele1/Allele2 Allele2/Allele2
genotype_counts <- c(0, 0, 0)
for (j in 1:nsamples) {
### indexes of genotypes for individual j
genotype_index <- c( (j*2)-1, (j*2) )
### count the Allele2 instances
genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
### increase the counter for the corresponding genotype
genotype_counts[genotype] <- genotype_counts[genotype] + 1
}
cat(" and genotype frequencies", genotype_counts)
}
nonHWE <- c() # to store indexes of SNPs deviating from HWE
nsamples <- 20
for (i in 1:ncol(data)) {
### alleles in this SNPs
alleles <- sort(unique(data[,i]))
cat("\nSNP", i )
### as before, I can choose one allele as "reference"
### frequency (of the second allele)
freq <- length(which(data[,i]==alleles[2])) / nrow(data)
### from the frequency, I can calculate the expected genotype counts under HWE
genotype_counts_expected <- c( (1-freq)^2, 2*freq*(1-freq), freq^2) * nsamples
### genotypes are Allele1/Allele1 Allele1/Allele2 Allele2/Allele2
genotype_counts <- c(0, 0, 0)
for (j in 1:nsamples) {
### indexes of genotypes for individual j
genotype_index <- c( (j*2)-1, (j*2) )
### count the Allele2 instances
genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
### increase the counter for the corresponding genotype
genotype_counts[genotype] <- genotype_counts[genotype] + 1
}
### test for HWE: calculate chi^2 statistic
chi <- sum( (genotype_counts_expected - genotype_counts)^2 / genotype_counts_expected )
## pvalue
pv <- 1 - pchisq(chi, df=1)
cat(" with pvalue for test against HWE", pv)
## retain SNPs with pvalue<0.05
if (pv < 0.05) nonHWE <- c(nonHWE, i)
}
### assuming we ran the code for point 5, we already have the SNPs deviating
F <- c()
nsamples <- 20
for (i in nonHWE) {
### alleles in this SNPs
alleles <- sort(unique(data[,i]))
cat("\nSNP", i)
### as before, I can choose one allele as "reference"
### frequency (of the second allele)
freq <- length(which(data[,i]==alleles[2])) / nrow(data)
### from the frequency, I can calculate the expected genotype counts under HWE
genotype_counts_expected <- c( (1-freq)^2, 2*freq*(1-freq), freq^2) * nsamples
### genotypes are Allele1/Allele1 Allele1/Allele2 Allele2/Allele2
genotype_counts <- c(0, 0, 0)
for (j in 1:nsamples) {
### indexes of genotypes for individual j
genotype_index <- c( (j*2)-1, (j*2) )
### count the Allele2 instances
genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
### increase the counter for the corresponding genotype
genotype_counts[genotype] <- genotype_counts[genotype] + 1
}
### calculate inbreeding coefficient
inbreeding <- ( 2*freq*(1-freq) - (genotype_counts[2]/nsamples) ) / ( 2*freq*(1-freq) )
F <- c(F, inbreeding)
cat(" with inbreeding coefficient", inbreeding)
}
### plot
hist(F)
plot(F, type="h")
source('~/Documents/CMEE_T2/T1_GenomicsBioinfo/File/2_solution_example_02.R')
View(data_b)
View(data_l)
View(data_w)
data_w <- read.csv("../Data/western_banded_gecko.csv", stringsAsFactors=F, header=F, colClasses=rep("character", len))
dim(data_w)
data_w <- read.csv("../Data/western_banded_gecko.csv", stringsAsFactors=F, header=T, colClasses=rep("character", len))
dim(data_w)
data_w <- read.csv("../Data/western_banded_gecko.csv", stringsAsFactors=F, header=F, colClasses=rep("character", len))
View(data_w)
cat("\nThe two species have a divergence time of", div_time, "years.")
cat("\nThe most likely species tree is L:(W:B).")
len <- 50000
data_N <- as.matrix(read.csv("../Data/killer_whale_North.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data_N)
data_S <- as.matrix(read.csv("../Data/killer_whale_South.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data_S)
View(data_S)
View(data_w)
View(data_S)
View(data_N)
len
### calculate nr of SNPs and then the estimator
freqs <- apply(X=data_N, MAR=2, FUN=sum)/nrow(data_N)
freqs
unique(freqs)
unique(which(freqs>0 & freqs<1))
which(freqs>0 & freqs<1)
unique(which(freqs>0 & freqs<1))
### North population
sfs_N <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_N, MAR=2, FUN=sum)
n <- nrow(data_N) # nr of samples (chromosomes)
### South population
sfs_S <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_S, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_S)) sfs_S[i] <- length(which(derived_freqs==i))
### plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(data_S)-1,1), legend=c("North", "South"))
### North population
sfs_N <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_N, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_N)) sfs_N[i] <- length(which(derived_freqs==i))
### South population
sfs_S <- rep(0, n-1)
### allele frequencies
derived_freqs <- apply(X=data_S, MAR=2, FUN=sum)
### the easiest (but slowest) thing to do would be to loop over all possible allele frequencies and count the occurrences
for (i in 1:length(sfs_S)) sfs_S[i] <- length(which(derived_freqs==i))
### plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(data_S)-1,1), legend=c("North", "South"))
cat("\nThe population with the greater population size has a higher proportion of singletons, as expected.")
which(derived_freqs==i)
length(which(derived_freqs==i))
sfs_N
length(sfs_N)
sfs <- matrix(0, nrow=nrow(data_N)+1, ncol=nrow(data_S)+1)
for (i in 1:ncol(data_N)) {
freq_N <- sum(data_N[,i])
freq_S <- sum(data_S[,i])
sfs[freq_N+1,freq_S+1] <- sfs[freq_N+1,freq_S+1] + 1
}
sfs[1,1] <- NA # ignore non-SNPs
image(t(sfs))
source('~/Documents/CMEE_T2/T1_GenomicsBioinfo/File/5_Solution_example_04.R')
### read data
len <- 2000
data <- as.matrix(read.csv("../Data/turtle.genotypes.csv", stringsAsFactors=F, header=F, colClasses=rep("numeric", len)))
dim(data)
### assign an name for each location
locations <- rep(c("A","B","C","D"), each=10)
distance <- dist(data)
tree <- hclust(distance)
plot(tree, labels=locations)
### or we can do a PCA
### we can filter our low-frequency variants first
colors <- rep(c("blue","red","yellow","green"), each=10)
plot(tree, labels=locations)
